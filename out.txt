Question 1 a)
######################################################################################################
For the Tsetlin model
---------------------
N = 4, c1 = 0.050, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 19027, action 2: 0
  performed action 1 19998 times, action 2 2 times
  performed action 1 100.0%, action 2 0.0%

For the Tsetlin model
---------------------
N = 4, c1 = 0.150, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 16999, action 2: 8
  performed action 1 19969 times, action 2 31 times
  performed action 1 99.8%, action 2 0.2%

For the Tsetlin model
---------------------
N = 4, c1 = 0.250, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 14818, action 2: 96
  performed action 1 19703 times, action 2 297 times
  performed action 1 98.5%, action 2 1.5%

For the Tsetlin model
---------------------
N = 4, c1 = 0.350, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 11975, action 2: 417
  performed action 1 18647 times, action 2 1353 times
  performed action 1 93.2%, action 2 6.8%

For the Tsetlin model
---------------------
N = 4, c1 = 0.450, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 9135, action 2: 939
  performed action 1 16765 times, action 2 3235 times
  performed action 1 83.8%, action 2 16.2%

For the Tsetlin model
---------------------
N = 4, c1 = 0.550, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 6086, action 2: 1859
  performed action 1 13736 times, action 2 6264 times
  performed action 1 68.7%, action 2 31.3%

For the Tsetlin model
---------------------
N = 4, c1 = 0.650, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 4045, action 2: 2660
  performed action 1 11281 times, action 2 8719 times
  performed action 1 56.4%, action 2 43.6%

######################################################################################################
Question 1 b)
######################################################################################################
c1 = 0.050, c2 = 0.700, for N = 2, p1(inf) = 0.995
c1 = 0.150, c2 = 0.700, for N = 2, p1(inf) = 0.956
c1 = 0.250, c2 = 0.700, for N = 3, p1(inf) = 0.958
c1 = 0.350, c2 = 0.700, for N = 5, p1(inf) = 0.966
c1 = 0.450, c2 = 0.700, for N = 9, p1(inf) = 0.953
0.55 0.7 no solution
0.65 0.7 no solution
######################################################################################################
Question 1 c)
######################################################################################################
For the Tsetlin model
---------------------
N = 2, c1 = 0.050, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 18921, action 2: 23
  performed action 1 19904 times, action 2 96 times
  performed action 1 99.5%, action 2 0.5%

For the Tsetlin model
---------------------
N = 2, c1 = 0.150, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 16249, action 2: 260
  performed action 1 19114 times, action 2 886 times
  performed action 1 95.6%, action 2 4.4%

For the Tsetlin model
---------------------
N = 3, c1 = 0.250, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 14448, action 2: 233
  performed action 1 19201 times, action 2 799 times
  performed action 1 96.0%, action 2 4.0%

For the Tsetlin model
---------------------
N = 5, c1 = 0.350, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 12537, action 2: 223
  performed action 1 19300 times, action 2 700 times
  performed action 1 96.5%, action 2 3.5%

For the Tsetlin model
---------------------
N = 9, c1 = 0.450, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 10492, action 2: 247
  performed action 1 19109 times, action 2 891 times
  performed action 1 95.5%, action 2 4.5%

For the Tsetlin model
---------------------
N = 100, c1 = 0.550, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 7186, action 2: 1252
  performed action 1 15934 times, action 2 4066 times
  performed action 1 79.7%, action 2 20.3%

For the Tsetlin model
---------------------
N = 400, c1 = 0.650, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 4103, action 2: 2506
  performed action 1 11597 times, action 2 8403 times
  performed action 1 58.0%, action 2 42.0%

c1 = 0.550, c2 = 0.700, for N = 100, p1(inf) = 0.800
c1 = 0.650, c2 = 0.700, for N = 400, p1(inf) = 0.571
######################################################################################################
Question 2
######################################################################################################
For the Krylov model
--------------------
N = 4, c1 = 0.050, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 18973, action 2: 0
  performed action 1 20000 times, action 2 0 times
  performed action 1 100.0%, action 2 0.0%

For the Tsetlin model
---------------------
N = 4, c1 = 0.025, c2 = 0.350
for the final 20000 iterations:
  rewards with action 1: 19463, action 2: 0
  performed action 1 20000 times, action 2 0 times
  performed action 1 100.0%, action 2 0.0%

*************
For the Krylov model
--------------------
N = 4, c1 = 0.150, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 17015, action 2: 0
  performed action 1 20000 times, action 2 0 times
  performed action 1 100.0%, action 2 0.0%

For the Tsetlin model
---------------------
N = 4, c1 = 0.075, c2 = 0.350
for the final 20000 iterations:
  rewards with action 1: 18545, action 2: 0
  performed action 1 20000 times, action 2 0 times
  performed action 1 100.0%, action 2 0.0%

*************
For the Krylov model
--------------------
N = 4, c1 = 0.250, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 15032, action 2: 0
  performed action 1 19994 times, action 2 6 times
  performed action 1 100.0%, action 2 0.0%

For the Tsetlin model
---------------------
N = 4, c1 = 0.125, c2 = 0.350
for the final 20000 iterations:
  rewards with action 1: 17135, action 2: 290
  performed action 1 19554 times, action 2 446 times
  performed action 1 97.8%, action 2 2.2%

*************
For the Krylov model
--------------------
N = 4, c1 = 0.350, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 12198, action 2: 344
  performed action 1 18843 times, action 2 1157 times
  performed action 1 94.2%, action 2 5.8%

For the Tsetlin model
---------------------
N = 4, c1 = 0.175, c2 = 0.350
for the final 20000 iterations:
  rewards with action 1: 16052, action 2: 327
  performed action 1 19488 times, action 2 512 times
  performed action 1 97.4%, action 2 2.6%

*************
For the Krylov model
--------------------
N = 4, c1 = 0.450, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 9228, action 2: 897
  performed action 1 16915 times, action 2 3085 times
  performed action 1 84.6%, action 2 15.4%

For the Tsetlin model
---------------------
N = 4, c1 = 0.225, c2 = 0.350
for the final 20000 iterations:
  rewards with action 1: 13951, action 2: 1344
  performed action 1 17861 times, action 2 2139 times
  performed action 1 89.3%, action 2 10.7%

*************
For the Krylov model
--------------------
N = 4, c1 = 0.550, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 7063, action 2: 1270
  performed action 1 15616 times, action 2 4384 times
  performed action 1 78.1%, action 2 21.9%

For the Tsetlin model
---------------------
N = 4, c1 = 0.275, c2 = 0.350
for the final 20000 iterations:
  rewards with action 1: 11162, action 2: 2890
  performed action 1 15470 times, action 2 4530 times
  performed action 1 77.3%, action 2 22.6%

*************
For the Krylov model
--------------------
N = 4, c1 = 0.650, c2 = 0.700
for the final 20000 iterations:
  rewards with action 1: 3879, action 2: 2627
  performed action 1 11131 times, action 2 8869 times
  performed action 1 55.7%, action 2 44.3%

For the Tsetlin model
---------------------
N = 4, c1 = 0.325, c2 = 0.350
for the final 20000 iterations:
  rewards with action 1: 8190, action 2: 5165
  performed action 1 12100 times, action 2 7900 times
  performed action 1 60.5%, action 2 39.5%

*************
######################################################################################################
Question 3 a)
######################################################################################################
For the L_RI model
------------------
k_r = 0.700, c1 = 0.050, c2 = 0.700
for the final 11 iterations:
  rewards with action 1: 7, action 2: 0
  performed action 1 7 times, action 2 4 times
  performed action 1 63.6%, action 2 36.4%
  final p1: 0.9588 final p2: 0.0412

For the L_RI model
------------------
k_r = 0.700, c1 = 0.150, c2 = 0.700
for the final 10 iterations:
  rewards with action 1: 7, action 2: 0
  performed action 1 8 times, action 2 2 times
  performed action 1 80.0%, action 2 20.0%
  final p1: 0.9588 final p2: 0.0412

For the L_RI model
------------------
k_r = 0.700, c1 = 0.250, c2 = 0.700
for the final 26 iterations:
  rewards with action 1: 14, action 2: 4
  performed action 1 17 times, action 2 9 times
  performed action 1 65.4%, action 2 34.6%
  final p1: 0.9611 final p2: 0.0389

For the L_RI model
------------------
k_r = 0.700, c1 = 0.350, c2 = 0.700
for the final 31 iterations:
  rewards with action 1: 11, action 2: 1
  performed action 1 21 times, action 2 10 times
  performed action 1 67.7%, action 2 32.3%
  final p1: 0.9578 final p2: 0.0422

For the L_RI model
------------------
k_r = 0.700, c1 = 0.450, c2 = 0.700
for the final 10 iterations:
  rewards with action 1: 7, action 2: 0
  performed action 1 9 times, action 2 1 times
  performed action 1 90.0%, action 2 10.0%
  final p1: 0.9588 final p2: 0.0412

For the L_RI model
------------------
k_r = 0.700, c1 = 0.550, c2 = 0.700
for the final 35 iterations:
  rewards with action 1: 4, action 2: 10
  performed action 1 9 times, action 2 26 times
  performed action 1 25.7%, action 2 74.3%
  final p1: 0.0467 final p2: 0.9533

For the L_RI model
------------------
k_r = 0.700, c1 = 0.650, c2 = 0.700
for the final 17 iterations:
  rewards with action 1: 0, action 2: 7
  performed action 1 3 times, action 2 14 times
  performed action 1 17.6%, action 2 82.4%
  final p1: 0.0412 final p2: 0.9588

Question 3 b)
######################################################################################################
L_RI optimal k_r is 0.598 for c1=0.05, c2=0.70 in 11 iterations
L_RI optimal k_r is 0.641 for c1=0.15, c2=0.70 in 14 iterations
L_RI optimal k_r is 0.685 for c1=0.25, c2=0.70 in 20 iterations
L_RI optimal k_r is 0.736 for c1=0.35, c2=0.70 in 30 iterations
L_RI optimal k_r is 0.796 for c1=0.45, c2=0.70 in 53 iterations
L_RI optimal k_r is 0.865 for c1=0.55, c2=0.70 in 130 iterations
L_RI optimal k_r is 0.950 for c1=0.65, c2=0.70 in 974 iterations
######################################################################################################
